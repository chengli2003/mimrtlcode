{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUY2iblcZTlT"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[all]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTcg8vu4yGMe",
        "outputId": "85f34899-dc5e-42fb-8961-5d747f0df66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n",
        "import einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDE9dhqiZWKM"
      },
      "outputs": [],
      "source": [
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    AsDiscreted,\n",
        "    EnsureChannelFirstd,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    CropForeground,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    RandCropByPosNegLabel,\n",
        "    RandAffined,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        "    EnsureTyped,\n",
        "    EnsureType,\n",
        "    Invertd,\n",
        "    LabelFilterd,\n",
        "    Resized\n",
        ")\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai.networks.nets import UNet, UNETR\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
        "from monai.config import print_config\n",
        "from monai.apps import download_and_extract\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLkmGxaTaZhs"
      },
      "outputs": [],
      "source": [
        "path_to_images='/content/drive/My Drive/MIMRTL Lab/Andy-labels'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqJZkEe-Zj8o",
        "outputId": "c69e5a20-64f1-49dd-c476-d422d8da2241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/My Drive/MIMRTL Lab/Andy-labels/51_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/52_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/53_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/54_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/55_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/56_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/57_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/58_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/59_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/60_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/61_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/62_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/63_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/64_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/65_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/66_CT.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/67_CT.nii.gz']\n",
            "['/content/drive/My Drive/MIMRTL Lab/Andy-labels/51_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/52_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/53_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/54_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/55_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/56_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/57_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/58_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/59_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/60_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/61_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/62_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/63_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/64_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/65_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/66_segmented.nii.gz', '/content/drive/My Drive/MIMRTL Lab/Andy-labels/67_segmented.nii.gz']\n"
          ]
        }
      ],
      "source": [
        "train_images = sorted(\n",
        "    glob.glob(os.path.join(path_to_images, '*_CT.nii.gz')))\n",
        "train_labels = sorted(\n",
        "    glob.glob(os.path.join(path_to_images, '*_segmented.nii.gz')))\n",
        "random.seed(1)\n",
        "print(train_images)\n",
        "print(train_labels)\n",
        "data_dicts = [\n",
        "    {\"image\": image_name, \"label\": label_name}\n",
        "    for image_name, label_name in zip(train_images, train_labels)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GNS68dAZdCk"
      },
      "outputs": [],
      "source": [
        "set_determinism(seed=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFm-rLZcZm5D",
        "outputId": "2ef6f2b7-c8a8-4310-c2af-38c8afcf0d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n"
          ]
        }
      ],
      "source": [
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
        "            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-1000, a_max=3000,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        RandCropByPosNegLabeld(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            label_key=\"label\",\n",
        "            spatial_size=(96, 96, 96),\n",
        "            pos=1,\n",
        "            neg=1,\n",
        "            num_samples=4,\n",
        "            image_key=\"image\",\n",
        "            image_threshold=0,\n",
        "        ),\n",
        "        # user can also add other random transforms\n",
        "        RandAffined(\n",
        "             keys=['image', 'label'],\n",
        "             mode=('bilinear', 'nearest'),\n",
        "             prob=1.0, spatial_size=(96, 96, 96),\n",
        "             rotate_range=(0, 0, np.pi/15),\n",
        "             scale_range=(0.1, 0.1, 0.1)),\n",
        "        LabelFilterd(keys=[\"label\"], applied_labels=(1)),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
        "            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-1000, a_max=3000,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        #Resized(keys=[\"image\", \"label\"], spatial_size=[128, 128, -1], \n",
        "        #        mode = [\"area\", \"nearest\"]),\n",
        "        LabelFilterd(keys=[\"label\"], applied_labels=(1)),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJtVTsJ8jhwb"
      },
      "outputs": [],
      "source": [
        "def load_data(trainIndex, testIndex):\n",
        "  train_files = []\n",
        "  val_files = []\n",
        "  for i in range(len(data_dicts)):\n",
        "    if i in trainIndex:\n",
        "      train_files.append(data_dicts[i])\n",
        "    else:\n",
        "      val_files.append(data_dicts[i])\n",
        "  train_ds = CacheDataset(\n",
        "      data=train_files, transform=train_transforms,\n",
        "      cache_rate=1.0, num_workers=4)\n",
        "  # train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "\n",
        "  # use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
        "  # to generate 2 x 4 images for network training\n",
        "  train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
        "\n",
        "  val_ds = CacheDataset(\n",
        "      data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
        "  # val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "  val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)\n",
        "  return (train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmxLj4odjj6H"
      },
      "outputs": [],
      "source": [
        "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "def create_model():\n",
        "  model = UNETR(\n",
        "      spatial_dims=3,\n",
        "      in_channels=1,\n",
        "      featu\n",
        "      out_channels=2,\n",
        "      img_size=(96, 96, 96),\n",
        "      norm_name='batch',\n",
        "  ).to(device)\n",
        "  loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
        "  dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "  return (model, loss_function, optimizer, dice_metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxL8-evwXgq5"
      },
      "outputs": [],
      "source": [
        "max_epochs = 200\n",
        "val_interval = 2\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
        "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
        "\n",
        "def fit(model, loss_function, optimizer, dice_metric, train_loader, val_loader, i):\n",
        "  for epoch in range(max_epochs):\n",
        "      print(\"-\" * 10)\n",
        "      print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "      model.train()\n",
        "      epoch_loss = 0\n",
        "      step = 0\n",
        "      for batch_data in train_loader:\n",
        "          step += 1\n",
        "          inputs, labels = (\n",
        "              batch_data[\"image\"].to(device),\n",
        "              batch_data[\"label\"].to(device),\n",
        "          )\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          loss = loss_function(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          epoch_loss += loss.item()\n",
        "          print(\n",
        "              f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
        "              f\"train_loss: {loss.item():.4f}\")\n",
        "      epoch_loss /= step\n",
        "      epoch_loss_values.append(epoch_loss)\n",
        "      print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "      if (epoch + 1) % val_interval == 0:\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "              for val_data in val_loader:\n",
        "                  val_inputs, val_labels = (\n",
        "                      val_data[\"image\"].to(device),\n",
        "                      val_data[\"label\"].to(device),\n",
        "                  )\n",
        "                  roi_size = (160, 160, 160)\n",
        "                  sw_batch_size = 4\n",
        "                  val_outputs = sliding_window_inference(\n",
        "                      val_inputs, roi_size, sw_batch_size, model)\n",
        "                  val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
        "                  val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
        "                  # compute metric for current iteration\n",
        "                  dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "              # aggregate the final mean dice result\n",
        "              metric = dice_metric.aggregate().item()\n",
        "              # reset the status for next validation round\n",
        "              dice_metric.reset()\n",
        "\n",
        "              metric_values.append(metric)\n",
        "              if metric > best_metric:\n",
        "                  best_metric = metric\n",
        "                  best_metric_epoch = epoch + 1\n",
        "                  torch.save(model.state_dict(), os.path.join(\n",
        "                      path_to_images, \"best_metric_model\" + str(i+1) + \".pth\"))\n",
        "                  print(\"saved new best metric model\")\n",
        "              print(\n",
        "                  f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
        "                  f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                  f\"at epoch: {best_metric_epoch}\"\n",
        "              )\n",
        "  print(\n",
        "      f\"train completed, best_metric: {best_metric:.4f} \"\n",
        "      f\"at epoch: {best_metric_epoch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qmu7MmlfXCJ"
      },
      "outputs": [],
      "source": [
        "val_org_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\"], pixdim=(\n",
        "            1.5, 1.5, 2.0), mode=\"bilinear\"),\n",
        "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-1000, a_max=3000,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        LabelFilterd(keys=[\"label\"], applied_labels=(1)),\n",
        "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "post_transforms = Compose([\n",
        "    EnsureTyped(keys=\"pred\"),\n",
        "    Invertd(\n",
        "        keys=\"pred\",\n",
        "        transform=val_org_transforms,\n",
        "        orig_keys=\"image\",\n",
        "        meta_keys=\"pred_meta_dict\",\n",
        "        orig_meta_keys=\"image_meta_dict\",\n",
        "        meta_key_postfix=\"meta_dict\",\n",
        "        nearest_interp=False,\n",
        "        to_tensor=True,\n",
        "    ),\n",
        "    ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=0.0, a_max=1.0,\n",
        "            b_min=-1000.0, b_max=3000.0, clip=True,\n",
        "        ),\n",
        "    AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
        "    AsDiscreted(keys=\"label\", to_onehot=2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymjKJ5xbfX8N"
      },
      "outputs": [],
      "source": [
        "def run_stats(testIndex, i):\n",
        "  model.load_state_dict(torch.load(\n",
        "      os.path.join(path_to_images, \"best_metric_model\" + str(i+1) + \".pth\")))\n",
        "  model.eval()\n",
        "  dataTest = []\n",
        "  for i in len(data_dicts):\n",
        "    if i in testIndex:\n",
        "      dataTest.append(data_dicts[i])\n",
        "  val_org_ds = Dataset(\n",
        "      data=dataTest, transform=val_org_transforms)\n",
        "  val_org_loader = DataLoader(val_org_ds, batch_size=1, num_workers=4)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for val_data in val_org_loader:\n",
        "        val_inputs = val_data[\"image\"].to(device)\n",
        "        roi_size = (160, 160, 160)\n",
        "        sw_batch_size = 4\n",
        "        val_data[\"pred\"] = sliding_window_inference(\n",
        "                  val_inputs, roi_size, sw_batch_size, model)\n",
        "        val_data = [post_transforms(i) for i in decollate_batch(val_data)]\n",
        "        subject = val_data[0][\"pred_meta_dict\"][\"filename_or_obj\"]\n",
        "        subject = subject.split(\"/\")\n",
        "        subject = subject[6].replace(\"_CT.nii.gz\", \"\")\n",
        "        val_images, val_outputs, val_labels = from_engine([\"image\", \"pred\", \"label\"])(val_data)\n",
        "        val_images = val_images[0][0]\n",
        "        val_outputs = val_outputs[0]\n",
        "        val_labels = val_labels[0]\n",
        "        mean = torch.mean(val_images[val_outputs[1] == 1])\n",
        "        std = torch.std(val_images[val_outputs[1] == 1])\n",
        "        # compute metric for current iteration\n",
        "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "        score = dice_metric.aggregate().item()\n",
        "        AllStats.append((subject, mean, std, score))\n",
        "        dice_metric.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHVko_dHN_jL",
        "outputId": "c501187c-7ee9-498c-9713-8dd0185eb99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Fold 1 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rLoading dataset:   0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# Initialize variables\n",
        "n = 10\n",
        "allStats = []\n",
        "\n",
        "# Implement KFold with n splits\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=n, shuffle=True)\n",
        "\n",
        "for i, (trainIndex, testIndex) in enumerate(kf.split(list(range(len(data_dicts))))):\n",
        "  print (\"Running Fold\", i+1, \"/\", n)\n",
        "  (train_loader, val_loader) = load_data(trainIndex, testIndex)\n",
        "  model = None\n",
        "  (model, loss_function, optimizer, dice_metric) = create_model()\n",
        "  fit(model, loss_function, optimizer, dice_metric, train_loader, val_loader, i)\n",
        "  run_stats(testIndex, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbspPKi4OlBl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MONAI Segmentation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}